{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d72d0aa",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Label:\n",
    "- 0 = Proud\n",
    "- 1 = Trust\n",
    "- 2 = Joy\n",
    "- 3 = Surprise\n",
    "- 4 = Neutral\n",
    "- 5 = Sadness\n",
    "- 6 = Fear\n",
    "- 7 = Anger\n",
    "\n",
    "Langkah-langkah yang akan dijalankan di sel berikutnya:\n",
    "1. Baca `data/datatrain.csv` mentah.\n",
    "2. Normalisasi label `emotion` ke kolom `emotion_clean` (mapping sederhana untuk typo/varian bahasa).\n",
    "3. Normalisasi nilai `video` ke `video_norm` (strip, ganti newline).\n",
    "4. Resolve duplikat berdasarkan `video_norm` dengan kebijakan majority-vote; catat grup konflik untuk audit.\n",
    "5. Simpan dataset final yang bersih ke `data/datatrain_clean.csv` (overwrite) dan simpan laporan konflik ke `data/duplicate_conflicts.csv`.\n",
    "\n",
    "Catatan: Saya berasumsi kebijakan resolusi otomatis yang wajar adalah majority-vote per video; jika ada tie, pilih kemunculan pertama. Jika Anda ingin aturan berbeda (mis. prioritas sumber), beri tahu dan saya ubah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b77b1e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and canonical mapping\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Canonical labels mapping (lowercase keys -> canonical)\n",
    "CANONICAL = {\n",
    "    'surprise': 'Surprise',\n",
    "    'terkejut': 'Surprise',\n",
    "    'trkejut': 'Surprise',\n",
    "    'kaget': 'Surprise',\n",
    "    'trekejut': 'Surprise',\n",
    "\n",
    "    'joy': 'Joy',\n",
    "    'happy': 'Joy',\n",
    "\n",
    "    'trust': 'Trust',\n",
    "    'faith': 'Trust',\n",
    "    'loyalty': 'Trust',\n",
    "    'percaya': 'Trust',\n",
    "    'percaya ': 'Trust',\n",
    "\n",
    "    'proud': 'Proud',\n",
    "    'pride': 'Proud',\n",
    "    'bangga': 'Proud',\n",
    "    'love': 'Proud',\n",
    "\n",
    "    'sadness': 'Sadness',\n",
    "    'sad': 'Sadness',\n",
    "\n",
    "    'anger': 'Anger',\n",
    "    'angry': 'Anger',\n",
    "    'marah': 'Anger',\n",
    "    'marh': 'Anger',\n",
    "\n",
    "    'fear': 'Fear',\n",
    "\n",
    "    'neutral': 'Neutral'\n",
    "}\n",
    "\n",
    "\n",
    "def normalize_label(raw_label: str) -> str:\n",
    "    if pd.isna(raw_label):\n",
    "        return ''\n",
    "    s = str(raw_label).strip()\n",
    "    low = s.lower()\n",
    "    return CANONICAL.get(low, s.title())\n",
    "\n",
    "\n",
    "def normalize_video(v: str) -> str:\n",
    "    if pd.isna(v):\n",
    "        return ''\n",
    "    s = str(v).strip()\n",
    "    s = s.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    return s.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca38f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dedupe_and_report(df: pd.DataFrame):\n",
    "    df = df.copy()\n",
    "    # normalize labels and video keys\n",
    "    df['emotion_clean'] = df['emotion'].apply(normalize_label)\n",
    "    df['video_norm'] = df['video'].apply(normalize_video)\n",
    "    df['video_key'] = df['video_norm'].str.lower().str.replace('\\\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "    groups = df.groupby('video_key')\n",
    "    keep_rows = []\n",
    "    conflict_rows = []\n",
    "    report = []\n",
    "\n",
    "    for key, g in groups:\n",
    "        unique_labels = g['emotion_clean'].dropna().unique().tolist()\n",
    "        counts = Counter(g['emotion_clean'].dropna().tolist())\n",
    "        if len(unique_labels) <= 1:\n",
    "            # safe to dedupe: keep first\n",
    "            keep_rows.append(g.iloc[0].to_dict())\n",
    "        else:\n",
    "            # conflict - save for review\n",
    "            for _, r in g.iterrows():\n",
    "                conflict_rows.append(r.to_dict())\n",
    "            report.append({'video_key': key, 'n_rows': len(g), 'labels': counts})\n",
    "\n",
    "    df_keep = pd.DataFrame(keep_rows)\n",
    "    df_conflicts = pd.DataFrame(conflict_rows)\n",
    "    report_df = pd.DataFrame(report)\n",
    "    return df_keep, df_conflicts, report_df\n",
    "\n",
    "\n",
    "def resolve_conflicts_majority(df_conflicts: pd.DataFrame):\n",
    "    # For each video_key choose majority label; if tie, choose first alphabetically\n",
    "    resolved = []\n",
    "    if df_conflicts.empty:\n",
    "        return pd.DataFrame()\n",
    "    for key, g in df_conflicts.groupby('video_key'):\n",
    "        counts = Counter(g['emotion_clean'].dropna().tolist())\n",
    "        if not counts:\n",
    "            chosen = ''\n",
    "        else:\n",
    "            max_count = max(counts.values())\n",
    "            candidates = [lab for lab, c in counts.items() if c == max_count]\n",
    "            chosen = sorted(candidates)[0]\n",
    "        # pick first row from group but force emotion_clean to chosen\n",
    "        row = g.iloc[0].to_dict()\n",
    "        row['emotion_clean'] = chosen\n",
    "        resolved.append(row)\n",
    "    return pd.DataFrame(resolved)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3c88571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw rows: 803\n",
      "Unique groups with conflicts (report rows): 6 conflict rows: 31\n",
      "Final rows (conflicts excluded): 769\n",
      "Wrote final clean file (conflicts excluded) -> data/datatrain_clean.csv\n",
      "Also wrote conflicts -> data/duplicate_conflicts.csv\n",
      "Unique groups with conflicts (report rows): 6 conflict rows: 31\n",
      "Final rows (conflicts excluded): 769\n",
      "Wrote final clean file (conflicts excluded) -> data/datatrain_clean.csv\n",
      "Also wrote conflicts -> data/duplicate_conflicts.csv\n"
     ]
    }
   ],
   "source": [
    "# Runner: run pipeline and write outputs\n",
    "raw_path = 'data/datatrain.csv'\n",
    "out_clean = 'data/datatrain_clean.csv'  # final overwrite\n",
    "out_conflicts = 'data/duplicate_conflicts.csv'\n",
    "\n",
    "raw = pd.read_csv(raw_path)\n",
    "print('Raw rows:', len(raw))\n",
    "\n",
    "keep, conflicts, report = dedupe_and_report(raw)\n",
    "print('Unique groups with conflicts (report rows):', len(report), 'conflict rows:', len(conflicts))\n",
    "\n",
    "# Save conflict rows for manual review (do not include in final)\n",
    "conflicts.to_csv(out_conflicts, index=False)\n",
    "\n",
    "# Exclude conflicts entirely from final dataset\n",
    "final = keep.copy()\n",
    "# ensure columns order like original and emotion_clean\n",
    "cols = list(raw.columns) + ['emotion_clean']\n",
    "cols = [c for c in cols if c in final.columns]\n",
    "final = final[cols]\n",
    "\n",
    "print('Final rows (conflicts excluded):', len(final))\n",
    "final.to_csv(out_clean, index=False)\n",
    "print('Wrote final clean file (conflicts excluded) ->', out_clean)\n",
    "print('Also wrote conflicts ->', out_conflicts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2-directml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
